{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install ftplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b585fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import library\n",
    "import datetime\n",
    "import time\n",
    "from ftplib import FTP\n",
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'anonymous'\n",
    "password = 'your email address'\n",
    "\n",
    "# Set start and end time, to filter last 5 years of files\n",
    "today = datetime.datetime.now()\n",
    "starttime = today.replace(day=1) - datetime.timedelta(days=1825)  # last 5 years\n",
    "endtime = today.replace(day=1) - datetime.timedelta(days=1)  # last month\n",
    "\n",
    "# Generate list of YYYY-MM dates\n",
    "date_list = []\n",
    "current_datetime = starttime\n",
    "while current_datetime <= endtime:\n",
    "    date_list.append(current_datetime.strftime('%Y%m'))\n",
    "    current_datetime += datetime.timedelta(days=31)  # Add one month\n",
    "\n",
    "print(\"List of YYYY-MM dates between start and end time:\")\n",
    "print(date_list)\n",
    "\n",
    "# Function to get observation locations from FTP server\n",
    "def get_observation_location(ftp_server, ftp_directory):\n",
    "    with FTP(ftp_server) as ftp:\n",
    "        ftp.login(username, password)\n",
    "        ftp.cwd(ftp_directory)\n",
    "        observe_locations_list = ftp.nlst()\n",
    "        return observe_locations_list\n",
    "\n",
    "# Function to download files from FTP server\n",
    "def download_files_from_ftp(ftp_server, ftp_directory, local_directory, observe_location, date_list):\n",
    "    with FTP(ftp_server) as ftp:\n",
    "        ftp.login(username, password)\n",
    "        ftp_directory_location = ftp_directory + observe_location + '/'\n",
    "        print(f\"Attempting to change directory to: {ftp_directory_location}\")\n",
    "\n",
    "        try:\n",
    "            ftp.cwd(ftp_directory_location)\n",
    "            print(f\"Successfully changed directory to: {ftp_directory_location}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: Failed to change directory to {ftp_directory_location}. Exception: {e}\")\n",
    "            return  # Exit if the directory cannot be changed\n",
    "\n",
    "        filenames = [f\"{observe_location}-{date}.csv\" for date in date_list]\n",
    "                    \n",
    "        for filename in filenames:\n",
    "            remote_filepath = filename\n",
    "            local_filepath = os.path.join(local_directory, filename)\n",
    "\n",
    "            try:\n",
    "                with open(local_filepath, \"wb\") as local_file:\n",
    "                    ftp.retrbinary(f\"RETR {remote_filepath}\", local_file.write)   \n",
    "                    print(f\"File '{remote_filepath}' downloaded to '{local_filepath}'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading file '{remote_filepath}': {e}\")\n",
    "\n",
    "# Define FTP server details\n",
    "ftp_server = \"ftp.bom.gov.au\"\n",
    "ftp_directory = \"/anon/gen/clim_data/IDCKWCDEA0/tables/sa/\"\n",
    "\n",
    "# Define local directory to save files\n",
    "local_directory = \"C://Users//rines//Capstone//Datasets\"\n",
    "\n",
    "# Ensure the local directory exists\n",
    "os.makedirs(local_directory, exist_ok=True)\n",
    "\n",
    "# Get observation locations from FTP server\n",
    "observe_locations = get_observation_location(ftp_server, ftp_directory)\n",
    "\n",
    "# Download files from FTP server\n",
    "for observe_location in observe_locations:\n",
    "    download_files_from_ftp(ftp_server, ftp_directory, local_directory, observe_location, date_list)\n",
    "    time.sleep(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the local directory containing the CSV files\n",
    "local_directory = \"C://Users//rines//Capstone//Datasets\"\n",
    "output_directory = \"C://Users//rines//Capstone//silver\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Get the list of files in the local directory\n",
    "filelist = os.listdir(local_directory)\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each location\n",
    "location_dfs = {}\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in filelist:\n",
    "    # Ignore files that don't match the expected pattern (e.g., avoid non-CSV files)\n",
    "    if not filename.endswith('.csv'):\n",
    "        print(f\"Skipping non-CSV file: {filename}\")\n",
    "        continue\n",
    "    \n",
    "    locationname = filename[:-11]  # Extract location name from the filename\n",
    "    \n",
    "    # Read the CSV file\n",
    "    temp = pd.read_csv(os.path.join(local_directory, filename), skiprows=13, encoding='utf-8', header=None)\n",
    "    \n",
    "    # Define the column names\n",
    "    columnname = ['station_name', 'date', 'ev_transpiration', 'rain', 'pan_ev', 'max_temp', 'min_temp', 'max_humid', 'min_humid', 'wind', 'solar']\n",
    "    temp.columns = columnname\n",
    "    \n",
    "    # Filter out rows that contain 'totals'\n",
    "    temp = temp[~temp['station_name'].str.contains('Totals:', case=False, na=False)]\n",
    "    \n",
    "    # If the location already has data, append to it; otherwise, create a new DataFrame\n",
    "    if locationname in location_dfs:\n",
    "        location_dfs[locationname] = pd.concat([location_dfs[locationname], temp], ignore_index=True)\n",
    "    else:\n",
    "        location_dfs[locationname] = temp\n",
    "\n",
    "# Save the merged DataFrame for each location to the output directory\n",
    "for locationname, df in location_dfs.items():\n",
    "    output_filepath = os.path.join(output_directory, f\"{locationname}.csv\")\n",
    "    df.to_csv(output_filepath, sep=',', encoding='utf-8', index=False)\n",
    "    print(f\"Processed and saved file: {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003eb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change directory and get list of file\n",
    "os.chdir(\"C://Users//rines//Capstone//silver\")\n",
    "\n",
    "filelist = os.listdir()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in filelist:\n",
    "    print(i)\n",
    "    temp = pd.read_csv(i, encoding='utf-8', index_col = 0)\n",
    "    df = pd.concat([df, temp], ignore_index=False)\n",
    "    del temp\n",
    "\n",
    "filepath = f'C://Users//rines//Capstone//All_Sa_weather_5_years.csv'\n",
    "        \n",
    "df.to_csv(filepath, sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
